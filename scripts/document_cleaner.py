#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
from pathlib import Path
from datetime import datetime

class DocumentCleaner:
    def __init__(self, docs_dir="docs"):
        self.docs_dir = Path(docs_dir)
        self.cleaned_files = []
        self.removed_files = []
        self.errors = []
        self.templates_dir = self.docs_dir / "templates"
        self.templates_dir.mkdir(exist_ok=True)
    
    def clean_all_documents(self):
        """æ¸…ç†æ‰€æœ‰æ–‡æ¡£"""
        print("ğŸ§¹ å¼€å§‹æ¸…ç†æ— å®è´¨å†…å®¹çš„æ–‡æ¡£...")
        
        # è¯†åˆ«éœ€è¦æ¸…ç†çš„æ–‡æ¡£
        candidates = self.identify_cleanup_candidates()
        
        # æ‰§è¡Œæ¸…ç†æ“ä½œ
        self.execute_cleanup(candidates)
        
        # ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
        self.generate_cleanup_report()
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼å¤„ç†äº† {len(candidates)} ä¸ªæ–‡æ¡£")
    
    def identify_cleanup_candidates(self):
        """è¯†åˆ«éœ€è¦æ¸…ç†çš„æ–‡æ¡£"""
        cleanup_candidates = []
        
        for md_file in self.docs_dir.rglob("*.md"):
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ£€æŸ¥æ–‡æ¡£ç±»å‹
                if self.is_template_document(content):
                    cleanup_candidates.append((md_file, "template", "æ¨¡æ¿æ–‡æ¡£"))
                elif self.is_empty_document(content):
                    cleanup_candidates.append((md_file, "empty", "ç©ºæ–‡æ¡£"))
                elif self.is_placeholder_document(content):
                    cleanup_candidates.append((md_file, "placeholder", "å ä½ç¬¦æ–‡æ¡£"))
                elif self.is_duplicate_document(content, md_file):
                    cleanup_candidates.append((md_file, "duplicate", "é‡å¤æ–‡æ¡£"))
                    
            except Exception as e:
                self.errors.append(f"Error processing {md_file}: {e}")
        
        return cleanup_candidates
    
    def is_template_document(self, content):
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡æ¿æ–‡æ¡£"""
        # æ›´ç²¾ç¡®çš„æ¨¡æ¿æ£€æµ‹é€»è¾‘
        template_patterns = [
            r'id:\s*evidence:PLACEHOLDER',  # è¯æ®æ¡ç›®æ¨¡æ¿
            r'PLACEHOLDER.*?å¾…å¡«å†™',  # æ˜ç¡®çš„å ä½ç¬¦
            r'æ¨¡æ¿.*?å¾…è¡¥å……',  # æ¨¡æ¿å¾…è¡¥å……
            r'ç¤ºä¾‹.*?å¾…å¡«å†™',  # ç¤ºä¾‹å¾…å¡«å†™
        ]
        
        # æ£€æŸ¥æ˜¯å¦ä¸»è¦æ˜¯æ¨¡æ¿ç»“æ„
        placeholder_count = len(re.findall(r'PLACEHOLDER|å¾…å¡«å†™|å¾…è¡¥å……|å ä½', content, re.IGNORECASE))
        total_lines = len(content.split('\n'))
        
        # å¦‚æœå ä½ç¬¦æ•°é‡è¶…è¿‡æ€»è¡Œæ•°çš„30%ï¼Œè®¤ä¸ºæ˜¯æ¨¡æ¿æ–‡æ¡£
        if placeholder_count > total_lines * 0.3:
            return True
            
        # æ£€æŸ¥ç‰¹å®šçš„æ¨¡æ¿æ¨¡å¼
        for pattern in template_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                return True
                
        return False
    
    def is_empty_document(self, content):
        """æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæ–‡æ¡£"""
        # ç§»é™¤ç©ºç™½å­—ç¬¦å’Œæ ‡é¢˜
        clean_content = re.sub(r'^#+\s*.*$', '', content, flags=re.MULTILINE)
        clean_content = re.sub(r'\s+', '', clean_content)
        
        return len(clean_content) < 100
    
    def is_duplicate_document(self, content, file_path):
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤æ–‡æ¡£"""
        # ç®€åŒ–çš„é‡å¤æ£€æµ‹é€»è¾‘
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é‡å¤çš„å†…å®¹æ¨¡å¼
        lines = content.split('\n')
        if len(lines) < 10:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤§é‡é‡å¤çš„è¡Œ
        line_counts = {}
        for line in lines:
            line = line.strip()
            if line and len(line) > 10:
                line_counts[line] = line_counts.get(line, 0) + 1
        
        # å¦‚æœæœ‰è¶…è¿‡30%çš„è¡Œæ˜¯é‡å¤çš„ï¼Œè®¤ä¸ºæ˜¯é‡å¤æ–‡æ¡£
        if line_counts:
            max_repeat = max(line_counts.values())
            if max_repeat > len(lines) * 0.3:
                return True
        
        return False
    
    def is_placeholder_document(self, content):
        """æ£€æŸ¥æ˜¯å¦ä¸ºå ä½ç¬¦æ–‡æ¡£"""
        placeholder_count = len(re.findall(r'TODO|FIXME|PLACEHOLDER|å¾…åŠ|å¾…è¡¥å……', content, re.IGNORECASE))
        return placeholder_count > 5
    
    def execute_cleanup(self, candidates):
        """æ‰§è¡Œæ¸…ç†æ“ä½œ"""
        for file_path, doc_type, description in candidates:
            try:
                print(f"ğŸ”§ å¤„ç† {doc_type}: {file_path}")
                
                if doc_type == "template":
                    self.handle_template_document(file_path)
                elif doc_type == "empty":
                    self.handle_empty_document(file_path)
                elif doc_type == "duplicate":
                    self.handle_duplicate_document(file_path)
                elif doc_type == "placeholder":
                    self.handle_placeholder_document(file_path)
                    
            except Exception as e:
                self.errors.append(f"Error cleaning {file_path}: {e}")
    
    def handle_template_document(self, file_path):
        """å¤„ç†æ¨¡æ¿æ–‡æ¡£"""
        # ç§»åŠ¨åˆ°templatesç›®å½•
        new_path = self.templates_dir / file_path.name
        file_path.rename(new_path)
        self.cleaned_files.append(f"Moved template: {file_path} -> {new_path}")
        print(f"  ğŸ“ ç§»åŠ¨åˆ°æ¨¡æ¿ç›®å½•: {new_path}")
    
    def handle_empty_document(self, file_path):
        """å¤„ç†ç©ºæ–‡æ¡£"""
        # åˆ é™¤ç©ºæ–‡æ¡£
        file_path.unlink()
        self.removed_files.append(f"Removed empty document: {file_path}")
        print(f"  ğŸ—‘ï¸ åˆ é™¤ç©ºæ–‡æ¡£: {file_path}")
    
    def handle_duplicate_document(self, file_path):
        """å¤„ç†é‡å¤æ–‡æ¡£"""
        # åˆ é™¤é‡å¤æ–‡æ¡£
        file_path.unlink()
        self.removed_files.append(f"Removed duplicate document: {file_path}")
        print(f"  ğŸ—‘ï¸ åˆ é™¤é‡å¤æ–‡æ¡£: {file_path}")
    
    def handle_placeholder_document(self, file_path):
        """å¤„ç†å ä½ç¬¦æ–‡æ¡£"""
        # å°è¯•ä¿®å¤æˆ–åˆ é™¤
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç§»é™¤å ä½ç¬¦
        cleaned_content = re.sub(r'TODO.*?\n', '', content, flags=re.IGNORECASE)
        cleaned_content = re.sub(r'FIXME.*?\n', '', cleaned_content, flags=re.IGNORECASE)
        cleaned_content = re.sub(r'PLACEHOLDER.*?\n', '', cleaned_content, flags=re.IGNORECASE)
        cleaned_content = re.sub(r'å¾…åŠ.*?\n', '', cleaned_content, flags=re.IGNORECASE)
        cleaned_content = re.sub(r'å¾…è¡¥å…….*?\n', '', cleaned_content, flags=re.IGNORECASE)
        
        if len(cleaned_content.strip()) > 100:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(cleaned_content)
            self.cleaned_files.append(f"Cleaned placeholder document: {file_path}")
            print(f"  âœ¨ æ¸…ç†å ä½ç¬¦: {file_path}")
        else:
            file_path.unlink()
            self.removed_files.append(f"Removed placeholder document: {file_path}")
            print(f"  ğŸ—‘ï¸ åˆ é™¤å ä½ç¬¦æ–‡æ¡£: {file_path}")
    
    def generate_cleanup_report(self):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        report = f"""# æ–‡æ¡£æ¸…ç†æŠ¥å‘Š

## æ¸…ç†æ¦‚è¿°

- **æ¸…ç†æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ¸…ç†æ–‡ä»¶æ•°**: {len(self.cleaned_files)}
- **åˆ é™¤æ–‡ä»¶æ•°**: {len(self.removed_files)}
- **é”™è¯¯æ•°**: {len(self.errors)}

## æ¸…ç†æ–‡ä»¶åˆ—è¡¨

"""
        
        if self.cleaned_files:
            report += "### å·²æ¸…ç†æ–‡ä»¶\n\n"
            for file_path in self.cleaned_files:
                report += f"- {file_path}\n"
        
        if self.removed_files:
            report += "\n### å·²åˆ é™¤æ–‡ä»¶\n\n"
            for file_path in self.removed_files:
                report += f"- {file_path}\n"
        
        if self.errors:
            report += "\n### é”™è¯¯åˆ—è¡¨\n\n"
            for error in self.errors:
                report += f"- {error}\n"
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self.docs_dir / "DOCUMENT_CLEANUP_REPORT.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“„ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description="Clean up documents with no substantial content.")
    parser.add_argument("--root", type=str, default="docs", help="Root directory to scan for Markdown files.")
    parser.add_argument("--dry-run", action="store_true", help="Show what would be cleaned without actually doing it.")
    args = parser.parse_args()
    
    cleaner = DocumentCleaner(args.root)
    
    if args.dry_run:
        print("ğŸ” é¢„è§ˆæ¨¡å¼ - æ˜¾ç¤ºå°†è¦æ¸…ç†çš„æ–‡æ¡£:")
        candidates = cleaner.identify_cleanup_candidates()
        for file_path, doc_type, description in candidates:
            print(f"  {doc_type}: {file_path}")
        print(f"\næ€»å…±æ‰¾åˆ° {len(candidates)} ä¸ªéœ€è¦æ¸…ç†çš„æ–‡æ¡£")
    else:
        cleaner.clean_all_documents()

if __name__ == "__main__":
    main()
